 徐涵W3China   2014-11-21 08:00
《黄智生博士谈语义网与Web 3.0》时隔多年，这篇5年前的访谈至今很大程度上仍然受用。@好东西传送门http://t.cn/RzA6G69
好东西传送门 转发于2014-11-21 10:10
在知识图谱已广为人知的今天，回顾这篇访谈很有必要。
Gary南京 转发于2014-11-22 06:57
谈语义Web最好不要把OWL和描述逻辑的作用过分夸大，因为本体不等于描述逻辑，语义Web的实现不一定要描述逻辑，描述逻辑很多东西在Web上是无用的
任远AI 转发于2014-11-22 07:04
OWL作为一个逻辑上的探索还是非常有价值的，提供了可计算性，完备性，正确性都有保障的情况下的一个表达能力的（近似）上界。
徐涵W3China 转发于2014-11-22 08:05
逻辑专家谈描述逻辑！
昊奋 转发于2014-11-22 08:48
任何时候都有符合当前潮流需要大力推广的技术，至少在这几年，基于描述逻辑和owl知识表示的任何技术还只能停留在科研范围，不过说不定过了几年又会得到重视，deep semantic或许是一个好的名字，也应该会走从shallow learning到deep learning发展的路。
Gary南京 转发于2014-11-22 10:22
OWL和描述逻辑只是众多推理和表示方法中的一种，其实没那么重要，之所以最近几年红火，只是学术界吹捧的，发了很多没什么用的论文，真正实用性是很差的，一旦没有实用性，就会被抛弃，这就是近两年来描述逻辑冷下去的原因，脱离实际的推理是不会有什么影响力的
昊奋 转发于2014-11-22 10:37
由漆教授作这样的逻辑推理专家做出如此反思和结论，更值得称赞，同时也比我等不做逻辑的人大谈特谈来得更能让人信服
Gary南京 转发于2014-11-22 10:48
呵呵，@昊奋 对推理的理解也是比较深的，我之所以说这些，是因为我不认为我自己的搞描述逻辑的，我不会把自己限制在某个门派，只要是有意思的东西都可以做，其实目前真正有用的还是早期的那些产生式规则、语义网络的东西
昊奋 转发于2014-11-22 11:05
回复@Gary南京:这种开放的精神值得赞
任远AI 转发于2014-11-22 12:04
赞同不应有门派之间。不过科研成果的实用性还是很难预计的。像语义网络在早期发展的时候也没特别大的影响力，这两年才在知识图谱之类的工业界应用上开始发挥作用。所以以后逻辑方法会有怎么样的前景还很不好说。
任远AI 转发于2014-11-22 12:09
如果漆教授可以再详细阐述一下描述逻辑之所以实用性差的问题核心，以及结合实际的推理技术应具备的特征，会是一个很有价值的课题！
昊奋 转发于2014-11-22 12:37
这个提议很好，不过挺难回答好，如果说清楚会对业界和学术界影响很大
Gary南京 转发于2014-11-22 13:21
这个要全面分析是很难的，我也是在思考当中，不过今年年初在Huddersfield的一个聚集了OWL推理的一些精英的研讨会上，大家对OWL的在大公司中是否有用的讨论中，发现其实很少有公司在用，其实OWL比较有用的也就DL-Lite, EL，就算这两个影响力其实是有限的。我说OWL实用性差就是基于此次讨论做的
Gary南京 转发于2014-11-22 13:26
另外，要注意的是，搞逻辑的总觉得自己的东西很有用，其实现在逻辑是基于知识库才有威力的，而真正有多少知识库是描述逻辑可以用的？知识获取的瓶颈突破不了，逻辑只是纸上谈兵而以，这就是KR不如ML和NLP的主要原因，而KR届真正意识到这点的人很少
任远AI 转发于2014-11-22 16:23
回复@Gary南京:我个人觉得描述逻辑的研究的出发点是相当有野心的，试图找出各种概念模型的一个可判定的最大“并集”，以此来解决异构知识的整合问题。可是工程和认知上实现并集的代价太大了，目前能做的其实只是各种模型的“交集”，这也是为什么越轻的DL相对越常用的原因。复杂DL只在极特定的领域可用
Gary南京 转发于2014-11-22 16:46
回复@任远AI:描述逻辑是否有用这个问题其实不需要去争论，因为肯定是有用的。不过在Web上，知识的表示是多样性的，描述逻辑只是其中一种而以，不需要过分的夸大，这就是我的观点，08年以前就是过分夸大了，照成泡沫，现在也差不多爆掉了
Gary南京 转发于2014-11-22 16:52
如果你去看看现在搞描述逻辑的人都在做什么你就会发现，所谓的OWL 2其实没多大影响力，大部分人都在搞DL-Lite, EL, OWL 2 RL，这其实就是对的，很多时候，越是简单的越实用。我其实对OWL 2一直就觉得没多大用，都是搞研究的人在空想的，应用中不一定是这样，只有根植于生活中的东西才有生命力
任远AI 转发于2014-11-22 16:55
KR和知识获取本来应该是相互依存的关系。但现在知识获取有瓶颈，KR的人等不下去，于是只能想象出一些情境来做研究。以后Linked Data和WikiData可能会给KR提供一个更扎实的基础。
Gary南京 转发于2014-11-22 16:59
表面上看是KR的人等不下去了，其实本质上是做KR的人没有应用驱动的去思考问题，只会去从理论方向去想问题，容易脱离实际，我觉得要真正做好KR，就需要去了解应用，而不是纸上谈兵。现在KR届的人思想太僵化，抱着自己的一某三分地不放，没有创新，最终很多组都会消亡
任远AI 转发于2014-11-22 17:02
这点我赞同，其实Ian和Franz早期搞DL的时候还是基于Galen和SNOMED之类的本体的，还是贴近实践的。只是搞逻辑的天生喜欢精巧复杂的东西，喜欢探讨理论上的可能性。这个算是KR领域的一个基因了。。。
任远AI 转发于2014-11-22 17:15
我觉得主要是逻辑这个圈子和工程师思维八字不合。像做ML或者NLP的可以说针对某个特定的应用对某个经典的模型进行改进提升了n%的精度。这种文章在KR里面是很难发的，你必须说你这个改进不是ad hoc的，有可推广性，是某种意义上的最优解。这就逼到理论的路子上去了。
任远AI 转发于2014-11-22 17:29
回复@Gary南京:哈哈哈深有同感。其实搞理论，搞证明，搞复杂的东西没啥错。为理论而理论，而证明而证明，而复杂而复杂就没必要的。有时候看到很多文章，框架定理一套套，证明了一堆很玄的东西，看得你热血沸腾，最后实质可以用的就那么一丁点。我就不说是谁了[doge][doge][doge]
昊奋 转发于2014-11-22 17:54
KR只是解决知识表示和知识模型的问题，但终究还有知识获取等问题。所以要成功，一定是开放，拥抱其他领域，针对具体的问题，踏踏实实的做出一些东西。ML和NLP的深入人心也是靠做出来的
昊奋 转发于2014-11-22 17:55
已经很明显地说明是谁了，[嘻嘻]
昊奋 转发于2014-11-22 18:01
一般要确定你做的是本体编辑还是ontology population还是ontology learning，对于编辑，可以用protégé或各种基于wiki的本体编辑，如果是population，如NELL等基于本体的学习算法可用，这时是生成实例，如果是最后一种情况，MPI的PATTY等可以参考，这种可以学习新的本体模式
Gary南京 转发于2014-11-22 18:03
回复@昊奋:是的，ML和NLP也很多灌水的论文，基本上没多大用，只是因为有应用支撑才红火起来的
任远AI 转发于2014-11-22 18:14
手工本体编辑很难规模化，大的本体都是十多年的努力才做成的。也许以后要用自动翻译之类的方法来生成本体
昊奋 转发于2014-11-22 18:17
所以在本体编辑的时候需要借助搜索或其他途径来获取现有相关本体并达到复用的目的。
昊奋 转发于2014-11-22 18:32
回复@anklebreaker11: 领域本体的构建请先查阅是否有相关的本体或者是否可以从通用的本体或知识库中抽取一个子集来获得。接着，再是类似NELL的方法来进一步扩充实例知识。
昊奋 转发于2014-11-22 18:48
回复@anklebreaker11: 医学领域比较复杂，不过你可以先了解一下LODD (linked open drug data) 以及 linked life science中涉及到的如snomed-ct等本体。另外，很多本体是包含中文标签的。当然如果涉及中医，可能需要更多依赖中文的资料，特别是医古文书籍等进行开放式抽取等。
 
​
